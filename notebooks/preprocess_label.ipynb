{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "file_path = '../telegram_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checking for NaN values in the 'Message' column:\")\n",
    "nan_count = df['Message'].isnull().sum()\n",
    "print(f\"Number of NaN values in 'Message' column: {nan_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = df.dropna(subset=['Message'])\n",
    "\n",
    "# Print the shape of the dataset after dropping NaN values in the \"Message\" column\n",
    "print(f\"Dataset shape after dropping NaN values in 'Message' column: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_df=df['Message']\n",
    "message_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define a function to remove emojis\n",
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\" \n",
    "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "        \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "        \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "        \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "        \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "        \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "        \"\\U000024C2-\\U0001F251\" \n",
    "        \"]+\", \n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "# Apply the function to the 'Message' column\n",
    "df['Message'] = df['Message'].apply(remove_emojis)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_message(message):\n",
    "    # Use regex to retain only Amharic characters, numbers, and spaces\n",
    "    message = re.sub(r'[^\\u1200-\\u137F0-9\\s]', '', message)  # Retain Amharic characters and numbers\n",
    "    message = re.sub(r'\\s+', ' ', message)  # Replace multiple spaces with one\n",
    "    \n",
    "    return message.strip()\n",
    "\n",
    "# Apply the preprocessing function to the 'Message' column\n",
    "df['Message'] = df['Message'].apply(preprocess_message)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Drop rows with missing values (if applicable)\n",
    "df = df.dropna()\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Drop rows with missing values (if applicable)\n",
    "df = df.dropna()\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def label_message_utf8_with_birr(message):\n",
    "    # Tokenize the message based on whitespace\n",
    "    tokens = re.findall(r'\\S+', message)\n",
    "    \n",
    "    labeled_tokens = []\n",
    "\n",
    "    # Initialize a variable to store the final labels\n",
    "    for i, token in enumerate(tokens):\n",
    "        # Default label is O\n",
    "        final_label = 'O'\n",
    "\n",
    "        # Check if the token is numeric (this is now for the cases you mentioned)\n",
    "        if re.match(r'^\\d+$', token):  # Only integers\n",
    "            price_before = (i > 0 and tokens[i - 1] in {'ETB', 'ዋጋ', '$', 'ብር'})\n",
    "            price_after = (i < len(tokens) - 1 and tokens[i + 1] in {'ETB', 'ዋጋ', '$', 'ብር'})\n",
    "            if price_before or price_after:\n",
    "                final_label = 'I-PRICE'\n",
    "\n",
    "        # Check if the token is a location\n",
    "        elif any(loc in token for loc in {\n",
    "            'ቁ2ፒያሳ', 'ቁ1መገናኛ', 'ጊዮርጊስ አደባባይ', 'ፒያሳ', \n",
    "            'ቅርንጫፍ', 'መሰረት ደፋር ሞል', 'ጊዮርጊስ', \n",
    "            'አደባባይ', 'ራመትታቦርኦዳህንፃ', 'መሰረት', 'ደፋር', 'ሞል'\n",
    "        }):\n",
    "            final_label = 'I-LOC'\n",
    "\n",
    "        # Append the labeled token to the list\n",
    "        labeled_tokens.append(f\"{token} {final_label}\")\n",
    "\n",
    "    return \"\\n\".join(labeled_tokens)\n",
    "\n",
    "# Sample DataFrame creation\n",
    "data = {\n",
    "    'Message': [\n",
    "        '0 Zemen Express® https://t.me/ZemenExpress 5352 ባለብዙጥቅም የመስታወት ጎድጓዳ ሳህኖች ከ ብርጭቆ የተሰራ ለቤተዎ ተጨማሪ ውበትን የሚሰጥ ለሳላድ እንዲሁም ለዎጥ ማቅረቢያ ተመራጭ ዋጋ፦ 450 ብር ውስን ፍሬ ነው ያለው አድራሻ ቁ1መገናኛ መሰረት ደፋር ሞል ሁለተኛ ፎቅ ቢሮ ቁ 0506 ቁ2ፒያሳ ጊዮርጊስ አደባባይ ራመትታቦርኦዳህንፃ 1ኛ ፎቅ ሱቅ ቁ 1 107 0902660722 0928460606 ፒያሳ ቅርንጫፍ 0941337070 በ ለማዘዝ ይጠቀሙ ለተጨማሪ ማብራሪያ የቴሌግራም ገፃችን 2024-09-30T09:20:55+00:00 photos\\\\httpstmeZemenExpress_5352jpg',\n",
    "        '1 Zemen Express® https://t.me/ZemenExpress 5351 ባለብዙጥቅም የመስታወት ጎድጓዳ ሳህኖች ከ ብርጭቆ የተሰራ ለቤተዎ ተጨማሪ ውበትን የሚሰጥ ለሳላድ እንዲሁም ለዎጥ ማቅረቢያ ተመራጭ ዋጋ፦ 450 ብር ውስን ፍሬ ነው ያለው አድራሻ ቁ1መገናኛ መሰረት ደፋር ሞል ሁለተኛ ፎቅ ቢሮ ቁ 0506 ቁ2ፒያሳ ጊዮርጊስ አደባባይ ራመትታቦርኦዳህንፃ 1ኛ ፎቅ ሱቅ ቁ 1 107 0902660722 0928460606 ፒያሳ ቅርንጫፍ 0941337070 በ ለማዘዝ ይጠቀሙ ለተጨማሪ ማብራሪያ የቴሌግራም ገፃችን 2024-09-30T09:20:47+00:00 photos\\\\httpstmeZemenExpress_5351jpg'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply the updated function to the messages in the DataFrame\n",
    "df['Labeled_Message'] = df['Message'].apply(label_message_utf8_with_birr)\n",
    "\n",
    "# Display the updated DataFrame with labeled messages\n",
    "print(df[['Message', 'Labeled_Message']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def label_message_utf8_with_birr(message):\n",
    "    # Tokenize the message\n",
    "    tokens = re.findall(r'\\S+', message)\n",
    "    \n",
    "    labeled_tokens = []\n",
    "\n",
    "    # Initialize a variable to store the final labels\n",
    "    final_labeled_tokens = []\n",
    "\n",
    "    # Iterate through tokens\n",
    "    for i, token in enumerate(tokens):\n",
    "        # Default label is O\n",
    "        final_label = 'O'\n",
    "\n",
    "        # Check if the token is a price based on context\n",
    "        if re.match(r'^\\d+(\\.\\d{1,2})?$', token):  # Numeric token check\n",
    "            price_before = (i > 0 and tokens[i - 1] in {'ETB', 'ዋጋ', '$', 'ብር'})\n",
    "            price_after = (i < len(tokens) - 1 and tokens[i + 1] in {'ETB', 'ዋጋ', '$', 'ብር'})\n",
    "            if price_before or price_after:\n",
    "                final_label = 'I-PRICE'\n",
    "        \n",
    "        # Check if the token is a location\n",
    "        elif any(loc in token for loc in {\n",
    "            'ቁ2ፒያሳ', 'ቁ1መገናኛ', 'ጊዮርጊስ አደባባይ', 'ፒያሳ', \n",
    "            'ቅርንጫፍ', 'መሰረት ደፋር ሞል', 'ጊዮርጊስ', \n",
    "            'አደባባይ', 'ራመትታቦርኦዳህንፃ', 'መሰረት', 'ደፋር', 'ሞል'\n",
    "        }):\n",
    "            final_label = 'I-LOC'\n",
    "\n",
    "        # Handle product labeling only if the label is not already set\n",
    "        if final_label == 'O' and i == 0:\n",
    "            final_label = 'B-PRODUCT'\n",
    "        elif final_label == 'O':\n",
    "            final_label = 'I-PRODUCT'\n",
    "\n",
    "        # Append the labeled token to the final list\n",
    "        final_labeled_tokens.append(f\"{token} {final_label}\")\n",
    "\n",
    "    return \"\\n\".join(final_labeled_tokens)\n",
    "\n",
    "\n",
    "# Apply the updated function to the messages in the DataFrame\n",
    "df['Labeled_Message'] = df['Message'].apply(label_message_utf8_with_birr)\n",
    "\n",
    "# Display the updated DataFrame with labeled messages\n",
    "print(df[['Message', 'Labeled_Message']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Message  \\\n",
      "0  0 Zemen Express® https://t.me/ZemenExpress 535...   \n",
      "1  1 Zemen Express® https://t.me/ZemenExpress 535...   \n",
      "\n",
      "                                     Labeled_Message  \n",
      "0  0 B-PRODUCT\\nZemen I-PRODUCT\\nExpress® I-PRODU...  \n",
      "1  1 B-PRODUCT\\nZemen I-PRODUCT\\nExpress® I-PRODU...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def label_message_utf8_with_birr(message):\n",
    "    # Tokenize the message based on whitespace\n",
    "    tokens = re.findall(r'\\S+', message)\n",
    "    \n",
    "    labeled_tokens = []\n",
    "    is_product_section = True  # Flag to track if we are in the product section\n",
    "\n",
    "    # Define keywords for prices and locations\n",
    "    price_keywords = {'ETB', 'ዋጋ', '$', 'ብር'}\n",
    "    location_keywords = {\n",
    "        'ቁ2ፒያሳ', 'ቁ1መገናኛ', 'ጊዮርጊስ አደባባይ', 'ፒያሳ', \n",
    "        'ቅርንጫፍ', 'መሰረት ደፋር ሞል', 'ጊዮርጊስ', \n",
    "        'አደባባይ', 'ራመትታቦርኦዳህንፃ', 'መሰረት', 'ደፋር', 'ሞል'\n",
    "    }\n",
    "\n",
    "    for i, token in enumerate(tokens):\n",
    "        # Check if we are still labeling as product\n",
    "        if is_product_section:\n",
    "            # Label the token as B-PRODUCT or I-PRODUCT\n",
    "            if labeled_tokens:  # If there are already labeled tokens, it's I-PRODUCT\n",
    "                labeled_tokens.append(f\"{token} I-PRODUCT\")\n",
    "            else:  # First token is labeled as B-PRODUCT\n",
    "                labeled_tokens.append(f\"{token} B-PRODUCT\")\n",
    "\n",
    "            # Check if this token is a price or location keyword\n",
    "            if token in price_keywords:\n",
    "                is_product_section = False  # Stop labeling as product and switch to price context\n",
    "            \n",
    "        else:\n",
    "            # Check if the token is a price (integers or decimals)\n",
    "            if re.match(r'^\\d+(\\.\\d+)?$', token):  # Matches integers or decimals\n",
    "                # If the last token was a price keyword, label the number as I-PRICE\n",
    "                if labeled_tokens and labeled_tokens[-1].split()[0] in price_keywords:\n",
    "                    labeled_tokens[-1] = f\"{labeled_tokens[-1].split()[0]} I-PRICE\"  # Update last token to be labeled as price\n",
    "                    labeled_tokens.append(f\"{token} I-PRICE\")\n",
    "                else:\n",
    "                    labeled_tokens.append(f\"{token} O\")  # Just O if not following a price keyword\n",
    "\n",
    "            # Check if the token is a location\n",
    "            elif token in location_keywords:\n",
    "                labeled_tokens.append(f\"{token} I-LOC\")\n",
    "            else:\n",
    "                labeled_tokens.append(f\"{token} O\")  # Everything else is O\n",
    "\n",
    "            # Handle cases where a price keyword is followed by a number\n",
    "            if i > 0 and tokens[i - 1] in price_keywords:\n",
    "                if re.match(r'^\\d+(\\.\\d+)?$', token):  # Handle case where number follows price keyword\n",
    "                    labeled_tokens[-1] = f\"{token} I-PRICE\"  # Update the last token to be labeled as price\n",
    "\n",
    "    return \"\\n\".join(labeled_tokens)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Apply the function to the messages in the DataFrame\n",
    "df['Labeled_Message'] = df['Message'].apply(label_message_utf8_with_birr)\n",
    "\n",
    "# Display the updated DataFrame with labeled messages\n",
    "print(df[['Message', 'Labeled_Message']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated labeled dataset to a file in CoNLL format\n",
    "labeled_data_birr_path = 'labeled_telegram_product_price_location.txt-'\n",
    "with open(labeled_data_birr_path, 'w', encoding='utf-8') as f:\n",
    "    for index, row in df.iterrows():\n",
    "        f.write(f\"{row['Labeled_Message']}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to preprocess messages and retain only Amharic text\n",
    "def preprocess_message(message):\n",
    "    # Use regex to retain only Amharic characters and spaces\n",
    "    message = re.sub(r'[^\\u1200-\\u137F\\s]', '', message)  # Retain only Amharic characters\n",
    "    message = re.sub(r'\\s+', ' ', message)  # Replace multiple spaces with one\n",
    "    \n",
    "    return message.strip()\n",
    "\n",
    "# Function to process the DataFrame\n",
    "def process_data(df):\n",
    "    processed_data = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        channel_title = row['Channel Title']\n",
    "        username = row['Channel Username']\n",
    "        message_id = row['ID']\n",
    "        message = row['Message']\n",
    "        date = row['Date']\n",
    "        media_path = row['Media Path']\n",
    "        \n",
    "        # Preprocess message if it's a string\n",
    "        cleaned_message = preprocess_message(message) if isinstance(message, str) else None\n",
    "        \n",
    "        # Convert date to datetime object if it's not None\n",
    "        date_obj = datetime.strptime(date, '%Y-%m-%d %H:%M:%S%z') if date else None\n",
    "        \n",
    "        # Store in structured format (dictionary here)\n",
    "        processed_data.append({\n",
    "            \"Channel Title\": channel_title,\n",
    "            \"Channel Username\": username,\n",
    "            \"Message ID\": message_id,\n",
    "            \"Message\": cleaned_message,\n",
    "            \"Date\": date_obj,\n",
    "            \"Media Path\": media_path\n",
    "        })\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "\n",
    "# Apply the function to process the DataFrame\n",
    "structured_data = process_data(data)\n",
    "\n",
    "# Create a new DataFrame from processed data\n",
    "df_processed = pd.DataFrame(structured_data)\n",
    "\n",
    "# Save the processed data to a new CSV file\n",
    "output_file_path = \"processed_data.csv\"  # Specify your output file name\n",
    "df_processed.to_csv(output_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Processed data has been saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
